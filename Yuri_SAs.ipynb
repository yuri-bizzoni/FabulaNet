{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09702c36-5444-4795-98f8-2ba63a8f386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pythons SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c90835-36fe-46f6-a2d6-8a01081902bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:22:55.483716Z",
     "iopub.status.busy": "2021-10-20T11:22:55.483117Z",
     "iopub.status.idle": "2021-10-20T11:24:24.409667Z",
     "shell.execute_reply": "2021-10-20T11:24:24.407832Z",
     "shell.execute_reply.started": "2021-10-20T11:22:55.483661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - nltk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2021.10.8  |       ha878542_0         139 KB  conda-forge\n",
      "    certifi-2021.10.8          |   py39hf3d152e_0         144 KB  conda-forge\n",
      "    click-8.0.3                |   py39hf3d152e_0         146 KB  conda-forge\n",
      "    joblib-1.1.0               |     pyhd8ed1ab_0         210 KB  conda-forge\n",
      "    nltk-3.6.5                 |     pyhd8ed1ab_0         1.1 MB  conda-forge\n",
      "    openssl-1.1.1l             |       h7f98852_0         2.1 MB  conda-forge\n",
      "    regex-2021.10.8            |   py39h3811e60_0         380 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  click              conda-forge/linux-64::click-8.0.3-py39hf3d152e_0\n",
      "  joblib             conda-forge/noarch::joblib-1.1.0-pyhd8ed1ab_0\n",
      "  nltk               conda-forge/noarch::nltk-3.6.5-pyhd8ed1ab_0\n",
      "  regex              conda-forge/linux-64::regex-2021.10.8-py39h3811e60_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2021.5.30-ha878542_0 --> 2021.10.8-ha878542_0\n",
      "  certifi                          2021.5.30-py39hf3d152e_0 --> 2021.10.8-py39hf3d152e_0\n",
      "  openssl                                 1.1.1k-h7f98852_1 --> 1.1.1l-h7f98852_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi-2021.10.8    | 144 KB    | ##################################### | 100% \n",
      "ca-certificates-2021 | 139 KB    | ##################################### | 100% \n",
      "openssl-1.1.1l       | 2.1 MB    | ##################################### | 100% \n",
      "nltk-3.6.5           | 1.1 MB    | ##################################### | 100% \n",
      "regex-2021.10.8      | 380 KB    | ##################################### | 100% \n",
      "joblib-1.1.0         | 210 KB    | ##################################### | 100% \n",
      "click-8.0.3          | 146 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install --yes nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c3024-f854-48bb-9223-2d58f6c7f2b4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-20T09:12:43.515275Z",
     "iopub.status.idle": "2021-10-20T09:12:43.516354Z",
     "shell.execute_reply": "2021-10-20T09:12:43.515911Z",
     "shell.execute_reply.started": "2021-10-20T09:12:43.515845Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66038b1-3dcf-4530-ae4d-0386c1a59170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:35.655223Z",
     "iopub.status.busy": "2021-10-20T11:47:35.653731Z",
     "iopub.status.idle": "2021-10-20T11:47:36.399943Z",
     "shell.execute_reply": "2021-10-20T11:47:36.398432Z",
     "shell.execute_reply.started": "2021-10-20T11:47:35.655144Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import sentiment\n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from importlib import reload\n",
    "import saffine\n",
    "reload(saffine)\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import saffine.multi_detrending as md\n",
    "import saffine.detrending_method as dm\n",
    "from metadata_parser import work_vals\n",
    "from scipy.stats import norm\n",
    "\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f1af2bf-8ff5-41e2-84d8-ef29f11a39dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:41.744542Z",
     "iopub.status.busy": "2021-10-20T11:47:41.743942Z",
     "iopub.status.idle": "2021-10-20T11:47:42.393099Z",
     "shell.execute_reply": "2021-10-20T11:47:42.392547Z",
     "shell.execute_reply.started": "2021-10-20T11:47:41.744493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ucloud/nltk_data...\n",
      "[nltk_data] Downloading package punkt to /home/ucloud/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbb07e05-4210-449b-8767-c6a639403a64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:42.399593Z",
     "iopub.status.busy": "2021-10-20T11:47:42.399469Z",
     "iopub.status.idle": "2021-10-20T11:47:42.410384Z",
     "shell.execute_reply": "2021-10-20T11:47:42.409919Z",
     "shell.execute_reply.started": "2021-10-20T11:47:42.399579Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer() #instantiates nltk's sentiment analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "985d718c-5017-4e5e-8d8a-54c707c7d4c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:43.657333Z",
     "iopub.status.busy": "2021-10-20T11:47:43.656831Z",
     "iopub.status.idle": "2021-10-20T11:47:43.665759Z",
     "shell.execute_reply": "2021-10-20T11:47:43.664942Z",
     "shell.execute_reply.started": "2021-10-20T11:47:43.657285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### short function to produce sentimental arcs\n",
    "\n",
    "def sentimarc(text, untokenized=True):\n",
    "    if untokenized:\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        print(len(sentences),\" sentences\")\n",
    "    else: sentences = text\n",
    "    sentimental_arc=[]\n",
    "    for sentence in sentences:\n",
    "        compound_polarity = sid.polarity_scores(sentence)['compound']\n",
    "        sentimental_arc.append(compound_polarity)\n",
    "    return sentimental_arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff549e1b-6ea5-4fff-b9fa-519d2eba437c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:44.041151Z",
     "iopub.status.busy": "2021-10-20T11:47:44.040153Z",
     "iopub.status.idle": "2021-10-20T11:47:44.063502Z",
     "shell.execute_reply": "2021-10-20T11:47:44.062868Z",
     "shell.execute_reply.started": "2021-10-20T11:47:44.041077Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Some functions Thelma's notebooks, but \"figures\" has an added hack to avoid an error \n",
    "# specific arc lengths used to throw. Also it returns the overall Hurst value\n",
    "\n",
    "def integrate(x):\n",
    "    return np.mat(np.cumsum(x) - np.mean(x))\n",
    "\n",
    "def normalize(ts, scl01 = False):\n",
    "    ts01 = (ts - np.min(ts)) / (np.max(ts) - np.min(ts))\n",
    "    ts11 = 2 * ts01 -1\n",
    "    if scl01:\n",
    "        return ts01\n",
    "    else:\n",
    "        return ts11\n",
    "    \n",
    "def optimal_bin(y):\n",
    "    \"\"\" optimal number of bins for histogram\n",
    "    src: https://academic.oup.com/biomet/article-abstract/66/3/605/232642\n",
    "    \"\"\"\n",
    "    R = max(y)-min(y)\n",
    "    n = len(y)\n",
    "    sigma = np.std(y)\n",
    "    return int(round((R * (n**(1./3.))) / (3.49 * sigma)))\n",
    "\n",
    "# functions to produce figures\n",
    "def figures(story_arc,sentimethod, workname, workid, neutral_score=0):\n",
    "    y = integrate(story_arc)\n",
    "    uneven = y.shape[1]%2\n",
    "    if uneven:\n",
    "        y = y[0,:-1]\n",
    "\n",
    "    # afa\n",
    "    #n = 500\n",
    "    step_size = 1\n",
    "    q = 3\n",
    "    order = 1\n",
    "    xy = md.multi_detrending(y, step_size, q, order)\n",
    "    ## slope\n",
    "    x = np.squeeze(np.asarray(xy[0]))\n",
    "    y = np.squeeze(np.asarray(xy[1]))\n",
    "\n",
    "    p = np.poly1d(np.polyfit(x, y, order))\n",
    "    xp = np.linspace(0, len(x), len(x))\n",
    "\n",
    "    #fig, ax = plt.subplots(2,1)\n",
    "\n",
    "    plt.figure(figsize=(12,20))\n",
    "    plt.subplot(311)\n",
    "    X = np.mat([float(x) for x in story_arc])\n",
    "    plt.plot(X.T,'-k', label = 'story arc')\n",
    "    n = len(story_arc)\n",
    "    w = int(4 * np.floor(n/20) + 1)\n",
    "\n",
    "    # format\n",
    "    for i in range(2,5):\n",
    "        try:\n",
    "            _, trend_ww_1 = dm.detrending_method(X, w, i)\n",
    "            plt.plot(normalize(trend_ww_1).T, label = \"$m = {}$\".format(str(i)))\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            X = np.mat([float(x) for x in story_arc+[neutral_score]])\n",
    "            plt.plot(X.T,'-k', label = 'story arc')\n",
    "            n = len(story_arc)\n",
    "            w = int(4 * np.floor(n/20) + 1)\n",
    "            pass\n",
    "           \n",
    "    plt.title(\"$%s~Story~Arc~{}$\".format(str(sentimethod)) % (workname))\n",
    "    plt.legend()\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$F(t)$')\n",
    "\n",
    "    plt.subplot(312)\n",
    "     # parameters\n",
    "        \n",
    "    for i in range(2,5):\n",
    "        _, trend_ww_1 = dm.detrending_method(X, w, i)\n",
    "        plt.plot(normalize(trend_ww_1).T, label = \"$m = {}$\".format(str(i)))\n",
    "\n",
    "    #plt.title(\"$Passing~Story~Arc_{Syuzhet}$\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('$t$')\n",
    "    plt.ylabel('$F(t)_{-1:1}$')\n",
    "    \n",
    "    plt.subplot(325)\n",
    "    M = np.mean(story_arc)\n",
    "    SD =  np.std(story_arc)\n",
    "    n, bins, _ = plt.hist(story_arc, optimal_bin(story_arc) ,density = True , facecolor = 'gray', edgecolor = 'w')\n",
    "    \n",
    "    Y = norm.pdf(bins, M, SD)\n",
    "    plt.plot(bins, Y, 'k-', linewidth=1.5)\n",
    "    plt.ylabel('$Sentiment~score$')\n",
    "    plt.ylabel('$Density$')\n",
    "\n",
    "    \n",
    "    plt.subplot(326)\n",
    "    plt.plot(xp, p(xp), 'k-', linewidth = 2,zorder = 0)\n",
    "    plt.scatter(x, y, c = 'r', s = 50, zorder = 1)\n",
    "    plt.title('$H = {}$'.format(round(np.polyfit(x, y, 1)[0],2)))\n",
    "    plt.xlabel('$Log(w)$')\n",
    "    plt.ylabel('$LogF(w)$')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    workname = re.sub(\"\\W+\",\" \", workname.lower())\n",
    "    workname = re.sub(\" +\", \"_\", workname)\n",
    "    workname = workname +\"_{}\".format(sentimethod)\n",
    "    workid = workid +\"_{}\".format(sentimethod)\n",
    "    ####plt.savefig(os.path.join(\"fig\", workid))\n",
    "    plt.savefig(workname+\".png\")\n",
    "    \n",
    "    plt.close()\n",
    "    \n",
    "    H = round(np.polyfit(x, y, 1)[0],2)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e666dec-aa27-4dc8-ac9f-fc6bfacf7440",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:44.212790Z",
     "iopub.status.busy": "2021-10-20T11:47:44.212187Z",
     "iopub.status.idle": "2021-10-20T11:47:44.938557Z",
     "shell.execute_reply": "2021-10-20T11:47:44.937531Z",
     "shell.execute_reply.started": "2021-10-20T11:47:44.212740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ugly Duckling\n",
      "The Princess and the Pea\n",
      "The Little Match-seller\n",
      "The Wild Swans\n",
      "The Swineherd\n",
      "Little Tiny or Thumbelina\n",
      "The Fir Tree\n",
      "The Snow Man\n",
      "The Brave Tin Soldier\n",
      "The Little Mermaid\n",
      "The Emperor's New Suit\n",
      "Jack the Dullard\n"
     ]
    }
   ],
   "source": [
    "##loop on the texts\n",
    "\n",
    "path_to_texts = \"andersen_subset/*.txt\"\n",
    "\n",
    "texts =[]\n",
    "for name in glob.glob(path_to_texts): \n",
    "    tale = open(name).read()\n",
    "    title = name.split(\"/\")[-1].split(\".\")[0]\n",
    "    print(title)\n",
    "    texts.append((title, tale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50445dbf-45f8-4ce6-bf26-b892fb1a0b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:44.958440Z",
     "iopub.status.busy": "2021-10-20T11:47:44.958309Z",
     "iopub.status.idle": "2021-10-20T11:47:53.373521Z",
     "shell.execute_reply": "2021-10-20T11:47:53.372900Z",
     "shell.execute_reply.started": "2021-10-20T11:47:44.958426Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ugly Duckling\n",
      "189  sentences\n",
      "The Princess and the Pea\n",
      "25  sentences\n",
      "error\n",
      "The Little Match-seller\n",
      "46  sentences\n",
      "The Wild Swans\n",
      "287  sentences\n",
      "The Swineherd\n",
      "95  sentences\n",
      "Little Tiny or Thumbelina\n",
      "192  sentences\n",
      "The Fir Tree\n",
      "185  sentences\n",
      "The Snow Man\n",
      "124  sentences\n",
      "The Brave Tin Soldier\n",
      "81  sentences\n",
      "error\n",
      "The Little Mermaid\n",
      "332  sentences\n",
      "The Emperor's New Suit\n",
      "95  sentences\n",
      "Jack the Dullard\n",
      "122  sentences\n",
      "CPU times: user 11.3 s, sys: 23.2 s, total: 34.5 s\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Sentence based sentimental arcs with nltk's Vader scores\n",
    "\n",
    "arcs = []\n",
    "for text in texts: \n",
    "    title, tale = text\n",
    "    print(title)\n",
    "    arc = sentimarc(tale)\n",
    "    arcs.append((title,arc))\n",
    "    Hurst_value = figures(arc, \"nltk_sentences\", title, \"0\") #we would prob. use a way to not save/plot everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d62c47a-4cc9-4bfb-826d-2b570f86fbcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:53.375214Z",
     "iopub.status.busy": "2021-10-20T11:47:53.375049Z",
     "iopub.status.idle": "2021-10-20T11:47:53.380326Z",
     "shell.execute_reply": "2021-10-20T11:47:53.379796Z",
     "shell.execute_reply.started": "2021-10-20T11:47:53.375198Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Ugly Duckling',\n",
       " 'The Princess and the Pea',\n",
       " 'The Little Match-seller',\n",
       " 'The Wild Swans',\n",
       " 'The Swineherd',\n",
       " 'Little Tiny or Thumbelina',\n",
       " 'The Fir Tree',\n",
       " 'The Snow Man',\n",
       " 'The Brave Tin Soldier',\n",
       " 'The Little Mermaid',\n",
       " \"The Emperor's New Suit\",\n",
       " 'Jack the Dullard']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a[0] for a in arcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a05aa51e-f536-41d1-87a4-0eb1b64c3410",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:47:53.381079Z",
     "iopub.status.busy": "2021-10-20T11:47:53.380938Z",
     "iopub.status.idle": "2021-10-20T11:48:01.152936Z",
     "shell.execute_reply": "2021-10-20T11:48:01.152398Z",
     "shell.execute_reply.started": "2021-10-20T11:47:53.381065Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ugly Duckling\n",
      "189 189\n",
      "Average score:  0.002982539682539689\n",
      "First score:  0.5672 \n",
      "Last score:  0.296\n",
      "H:  0.61\n",
      "\n",
      "The Princess and the Pea\n",
      "25 25\n",
      "Average score:  -0.029635999999999996\n",
      "First score:  0.0 \n",
      "Last score:  0.4215\n",
      "error\n",
      "H:  0.63\n",
      "\n",
      "The Little Match-seller\n",
      "46 46\n",
      "Average score:  0.13603695652173914\n",
      "First score:  -0.6369 \n",
      "Last score:  -0.0387\n",
      "H:  0.69\n",
      "\n",
      "The Wild Swans\n",
      "287 287\n",
      "Average score:  0.07832020905923344\n",
      "First score:  0.0 \n",
      "Last score:  -0.296\n",
      "H:  0.57\n",
      "\n",
      "The Swineherd\n",
      "95 95\n",
      "Average score:  0.14164105263157897\n",
      "First score:  -0.2617 \n",
      "Last score:  0.5106\n",
      "H:  0.63\n",
      "\n",
      "Little Tiny or Thumbelina\n",
      "192 192\n",
      "Average score:  0.13950156249999998\n",
      "First score:  -0.438 \n",
      "Last score:  0.0\n",
      "H:  0.6\n",
      "\n",
      "The Fir Tree\n",
      "185 185\n",
      "Average score:  0.15637027027027026\n",
      "First score:  0.8361 \n",
      "Last score:  0.0\n",
      "H:  0.57\n",
      "\n",
      "The Snow Man\n",
      "124 124\n",
      "Average score:  0.09159193548387098\n",
      "First score:  0.6948 \n",
      "Last score:  0.0\n",
      "H:  0.6\n",
      "\n",
      "The Brave Tin Soldier\n",
      "81 81\n",
      "Average score:  0.05664938271604938\n",
      "First score:  0.6289 \n",
      "Last score:  0.0\n",
      "error\n",
      "H:  0.63\n",
      "\n",
      "The Little Mermaid\n",
      "332 332\n",
      "Average score:  0.19523825301204817\n",
      "First score:  0.6157 \n",
      "Last score:  -0.916\n",
      "H:  0.6\n",
      "\n",
      "The Emperor's New Suit\n",
      "95 95\n",
      "Average score:  0.13670736842105263\n",
      "First score:  0.2732 \n",
      "Last score:  0.6369\n",
      "H:  0.49\n",
      "\n",
      "Jack the Dullard\n",
      "122 122\n",
      "Average score:  0.020622950819672133\n",
      "First score:  -0.0857 \n",
      "Last score:  0.0\n",
      "H:  0.53\n",
      "\n",
      "CPU times: user 10.8 s, sys: 19.7 s, total: 30.4 s\n",
      "Wall time: 7.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Sentence based sentimental arcs with nltk's Vader scores\n",
    "\n",
    "Hs={} #Dictionary to store Hurst values\n",
    "\n",
    "\n",
    "out = open(\"sentence_sentiments.txt\",\"w\") #output file \n",
    "\n",
    "for text_t in texts:\n",
    "    title, text = text_t\n",
    "    out.write(title+\"\\n\")\n",
    "    print(title)\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "    s_arc = [sid.polarity_scores(sentence)[\"compound\"] for sentence in sentences]\n",
    "    \n",
    "    #word_arc = [sid.polarity_scores(w)[\"compound\"] for w in words]\n",
    "    \n",
    "    print(len(sentences),len(s_arc))\n",
    "    print(\"Average score: \", np.mean(s_arc))\n",
    "    print(\"First score: \",s_arc[0],\"\\nLast score: \",s_arc[-1])\n",
    "    if len(s_arc)>20: H=figures(s_arc,\"ntlk_V\",title+\"_words\",\"w\")\n",
    "    print(\"H: \",str(H))\n",
    "    out.write(str(s_arc))\n",
    "    out.write(\"\\n\"+str(H))\n",
    "    out.write(\"\\n\\n\")\n",
    "    \n",
    "    Hs[title]=[H]\n",
    "    \n",
    "    print()\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ceac677-8596-42b6-8bd5-fb6a9f50e105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:48:01.166949Z",
     "iopub.status.busy": "2021-10-20T11:48:01.166826Z",
     "iopub.status.idle": "2021-10-20T11:48:07.993796Z",
     "shell.execute_reply": "2021-10-20T11:48:07.993244Z",
     "shell.execute_reply.started": "2021-10-20T11:48:01.166935Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ugly Duckling\n",
      "4507 276\n",
      "Average score:  0.028526449275362315\n",
      "First score:  0.5859 \n",
      "Last score:  -0.5106\n",
      "H:  0.7\n",
      "\n",
      "The Princess and the Pea\n",
      "446 14\n",
      "Average score:  -0.12212857142857146\n",
      "First score:  -0.3612 \n",
      "Last score:  0.4215\n",
      "H:  0.7\n",
      "\n",
      "The Little Match-seller\n",
      "1170 65\n",
      "Average score:  0.12561692307692307\n",
      "First score:  -0.5574 \n",
      "Last score:  0.5423\n",
      "H:  0.76\n",
      "\n",
      "The Wild Swans\n",
      "7364 361\n",
      "Average score:  0.08266814404432132\n",
      "First score:  0.34 \n",
      "Last score:  -0.296\n",
      "error\n",
      "H:  0.65\n",
      "\n",
      "The Swineherd\n",
      "1862 106\n",
      "Average score:  0.1740160377358491\n",
      "First score:  -0.4767 \n",
      "Last score:  0.5106\n",
      "H:  0.59\n",
      "\n",
      "Little Tiny or Thumbelina\n",
      "5143 292\n",
      "Average score:  0.13879931506849316\n",
      "First score:  0.4019 \n",
      "Last score:  0.2263\n",
      "H:  0.64\n",
      "\n",
      "The Fir Tree\n",
      "3964 203\n",
      "Average score:  0.19528128078817733\n",
      "First score:  0.2263 \n",
      "Last score:  0.6369\n",
      "H:  0.66\n",
      "\n",
      "The Snow Man\n",
      "2457 101\n",
      "Average score:  0.2191930693069307\n",
      "First score:  0.5719 \n",
      "Last score:  -0.4215\n",
      "error\n",
      "H:  0.73\n",
      "\n",
      "The Brave Tin Soldier\n",
      "2032 78\n",
      "Average score:  0.08982692307692308\n",
      "First score:  0.2263 \n",
      "Last score:  0.3612\n",
      "H:  0.68\n",
      "\n",
      "The Little Mermaid\n",
      "10570 614\n",
      "Average score:  0.18122605863192182\n",
      "First score:  0.5719 \n",
      "Last score:  -0.5267\n",
      "H:  0.71\n",
      "\n",
      "The Emperor's New Suit\n",
      "1880 118\n",
      "Average score:  0.21320677966101698\n",
      "First score:  0.2732 \n",
      "Last score:  0.4019\n",
      "H:  0.63\n",
      "\n",
      "Jack the Dullard\n",
      "2028 67\n",
      "Average score:  0.16830447761194028\n",
      "First score:  0.4588 \n",
      "Last score:  0.5106\n",
      "H:  0.53\n",
      "\n",
      "CPU times: user 10.3 s, sys: 21.7 s, total: 32 s\n",
      "Wall time: 6.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Word-by-word sentimental arcs with nltk's Vader scores\n",
    "\n",
    "Hs={} #Dictionary to store Hurst values\n",
    "\n",
    "\n",
    "out = open(\"word_filtered_sentiments_Vader.txt\",\"w\") #output file \n",
    "\n",
    "for text_t in texts:\n",
    "    title, text = text_t\n",
    "    out.write(title+\"\\n\")\n",
    "    print(title)\n",
    "    words = nltk.wordpunct_tokenize(text)\n",
    "    \n",
    "    #Here I only keep words that are in sid's lexicon. So no neutral words\n",
    "    words_in_sid_lexicon = [w for w in words if w in sid.lexicon.keys()] \n",
    "    \n",
    "    word_arc = [sid.polarity_scores(w)[\"compound\"] for w in words_in_sid_lexicon]\n",
    "    \n",
    "    #word_arc = [sid.polarity_scores(w)[\"compound\"] for w in words]\n",
    "    \n",
    "    print(len(words),len(word_arc))\n",
    "    print(\"Average score: \", np.mean(word_arc))\n",
    "    print(\"First score: \",word_arc[0],\"\\nLast score: \",word_arc[-1])\n",
    "    if len(word_arc)>20: H=figures(word_arc,\"ntlk_V\",title+\"_words\",\"w\")\n",
    "    print(\"H: \",str(H))\n",
    "    out.write(str(word_arc))\n",
    "    out.write(\"\\n\"+str(H))\n",
    "    out.write(\"\\n\\n\")\n",
    "    \n",
    "    Hs[title]=[H]\n",
    "    \n",
    "    print()\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c33a92-2adb-48db-8f28-8c747d3274f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:48:09.423424Z",
     "iopub.status.busy": "2021-10-20T11:48:09.422605Z",
     "iopub.status.idle": "2021-10-20T11:48:09.430345Z",
     "shell.execute_reply": "2021-10-20T11:48:09.429362Z",
     "shell.execute_reply.started": "2021-10-20T11:48:09.423372Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[0.7], [0.7], [0.76], [0.65], [0.59], [0.64], [0.66], [0.73], [0.68], [0.71], [0.63], [0.53]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8805a2e1-f96b-4861-ac46-5340d4ddc464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:48:09.968612Z",
     "iopub.status.busy": "2021-10-20T11:48:09.968122Z",
     "iopub.status.idle": "2021-10-20T11:48:10.037415Z",
     "shell.execute_reply": "2021-10-20T11:48:10.036359Z",
     "shell.execute_reply.started": "2021-10-20T11:48:09.968564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### To compare VAD scores, I create a VAD dictionary\n",
    "\n",
    "#\"/Users/au701203/Downloads/NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt\"\n",
    "\n",
    "path_to_the_lexicon = \"NRC-VAD-Lexicon.txt\"\n",
    "\n",
    "VAD = open(path_to_the_lexicon).read()\n",
    "lines = VAD.split(\"\\n\")\n",
    "tabs = [l.split(\"\\t\") for l in lines]\n",
    "tabs = [t for t in tabs if len(t)==4]\n",
    "Vadscores = {}\n",
    "for tab in tabs:\n",
    "    Vadscores[tab[0]]=float(tab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c10651-3408-48e6-9513-888a7f6d6983",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:48:10.232687Z",
     "iopub.status.busy": "2021-10-20T11:48:10.232244Z",
     "iopub.status.idle": "2021-10-20T11:48:10.240763Z",
     "shell.execute_reply": "2021-10-20T11:48:10.239863Z",
     "shell.execute_reply.started": "2021-10-20T11:48:10.232641Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.948"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vadscores[\"glory\"]  #Vad scores' minimum is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11363b2b-6e13-421f-b43f-8f4cbfe7449b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:48:10.408041Z",
     "iopub.status.busy": "2021-10-20T11:48:10.407563Z",
     "iopub.status.idle": "2021-10-20T11:48:10.472590Z",
     "shell.execute_reply": "2021-10-20T11:48:10.471387Z",
     "shell.execute_reply.started": "2021-10-20T11:48:10.407993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### VAD arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8ba8187-b9fe-440e-b83f-256464bdee5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T09:40:49.537332Z",
     "iopub.status.busy": "2021-10-20T09:40:49.536357Z",
     "iopub.status.idle": "2021-10-20T09:41:31.114446Z",
     "shell.execute_reply": "2021-10-20T09:41:31.113707Z",
     "shell.execute_reply.started": "2021-10-20T09:40:49.537213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ugly Duckling\n",
      "4507 1174\n",
      "[0.917, 0.812, 0.755, 0.698, 0.802, 0.594, 0.63, 0.875, 0.708, 0.541]\n",
      "Average happiness:  0.5891669505962521\n",
      "First score:  0.917 \n",
      "Last score:  0.602\n",
      "H:  0.63\n",
      "\n",
      "The Princess and the Pea\n",
      "446 108\n",
      "[0.604, 0.888, 0.896, 0.885, 0.493, 0.757, 0.67, 0.719, 0.885, 0.622]\n",
      "Average happiness:  0.6107777777777779\n",
      "First score:  0.604 \n",
      "Last score:  0.653\n",
      "H:  0.66\n",
      "\n",
      "The Little Match-seller\n",
      "1170 325\n",
      "[0.061, 0.398, 0.198, 0.458, 0.542, 0.667, 0.202, 0.398, 0.102, 0.156]\n",
      "Average happiness:  0.5582738461538462\n",
      "First score:  0.061 \n",
      "Last score:  0.719\n",
      "H:  0.57\n",
      "\n",
      "The Wild Swans\n",
      "7364 1898\n",
      "[0.582, 0.76, 0.663, 0.677, 0.449, 0.542, 0.908, 0.562, 0.449, 0.765]\n",
      "Average happiness:  0.6014199157007376\n",
      "First score:  0.582 \n",
      "Last score:  0.677\n",
      "H:  0.63\n",
      "\n",
      "The Swineherd\n",
      "1862 443\n",
      "[0.604, 0.156, 0.888, 0.714, 0.542, 0.704, 0.76, 0.896, 0.896, 0.493]\n",
      "Average happiness:  0.6197968397291196\n",
      "First score:  0.604 \n",
      "Last score:  0.385\n",
      "H:  0.53\n",
      "\n",
      "Little Tiny or Thumbelina\n",
      "5143 1392\n",
      "[0.757, 0.385, 0.912, 0.76, 0.771, 0.776, 0.719, 0.757, 0.385, 0.912]\n",
      "Average happiness:  0.6045847701149425\n",
      "First score:  0.757 \n",
      "Last score:  0.653\n",
      "H:  0.62\n",
      "\n",
      "The Fir Tree\n",
      "3964 971\n",
      "[0.208, 0.729, 0.76, 0.877, 0.908, 0.708, 0.668, 0.573, 0.875, 0.385]\n",
      "Average happiness:  0.6183367662203914\n",
      "First score:  0.208 \n",
      "Last score:  0.198\n",
      "H:  0.61\n",
      "\n",
      "The Snow Man\n",
      "2457 583\n",
      "[0.398, 0.653, 0.694, 0.327, 0.918, 0.531, 0.316, 0.918, 0.542, 0.958]\n",
      "Average happiness:  0.6055969125214409\n",
      "First score:  0.398 \n",
      "Last score:  0.78\n",
      "H:  0.57\n",
      "\n",
      "The Brave Tin Soldier\n",
      "2032 546\n",
      "[0.51, 0.52, 0.469, 0.469, 0.479, 0.464, 0.896, 0.57, 0.427, 0.646]\n",
      "Average happiness:  0.5421904761904761\n",
      "First score:  0.51 \n",
      "Last score:  0.35\n",
      "H:  0.63\n",
      "\n",
      "The Little Mermaid\n",
      "10570 2971\n",
      "[0.823, 0.812, 0.646, 0.857, 0.618, 0.49, 0.49, 0.583, 0.52, 0.708]\n",
      "Average happiness:  0.6324554022214742\n",
      "First score:  0.823 \n",
      "Last score:  0.438\n",
      "H:  0.66\n",
      "\n",
      "The Emperor's New Suit\n",
      "1880 465\n",
      "[0.653, 0.317, 0.651, 0.78, 0.917, 0.833, 0.296, 0.844, 0.78, 0.76]\n",
      "Average happiness:  0.6248602150537633\n",
      "First score:  0.653 \n",
      "Last score:  0.857\n",
      "H:  0.54\n",
      "\n",
      "Jack the Dullard\n",
      "2028 432\n",
      "[0.618, 0.698, 0.521, 0.51, 0.735, 0.52, 0.52, 0.78, 0.896, 0.5]\n",
      "Average happiness:  0.6111805555555555\n",
      "First score:  0.618 \n",
      "Last score:  0.67\n",
      "H:  0.51\n",
      "\n",
      "CPU times: user 34.8 s, sys: 1min 39s, total: 2min 14s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Vader word-by-word sentiment arcs using VAD scores\n",
    "\n",
    "out = open(\"word_filtered_sentiments_VAD.txt\",\"w\")\n",
    "\n",
    "for text_t in texts:\n",
    "    title, text = text_t\n",
    "    print(title)\n",
    "    words = nltk.wordpunct_tokenize(text)\n",
    "    \n",
    "    #Using VAD's lexicon\n",
    "    words_in_vad_lexicon = [w for w in words if w in Vadscores.keys()]\n",
    "    word_arc = [Vadscores[w] for w in words_in_vad_lexicon]\n",
    "    \n",
    "    print(len(words),len(word_arc))\n",
    "    \n",
    "    print(word_arc[:10])\n",
    "    print(\"Average happiness: \", np.mean(word_arc))\n",
    "    print(\"First score: \",word_arc[0],\"\\nLast score: \",word_arc[-1])\n",
    "    if len(word_arc)>20: H=figures(word_arc,\"VAD\",title+\"_words\",\"w\")\n",
    "    print(\"H: \",str(H))\n",
    "    out.write(str(word_arc))\n",
    "    out.write(\"\\n\"+str(H))\n",
    "    out.write(\"\\n\\n\")\n",
    "    \n",
    "    Hs[title].append(H)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c546a38d-d9af-4b03-9292-b638d0e8806c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T09:41:50.278292Z",
     "iopub.status.busy": "2021-10-20T09:41:50.277453Z",
     "iopub.status.idle": "2021-10-20T09:41:50.294411Z",
     "shell.execute_reply": "2021-10-20T09:41:50.293562Z",
     "shell.execute_reply.started": "2021-10-20T09:41:50.278178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Ugly Duckling': [0.7, 0.63],\n",
       " 'The Princess and the Pea': [0.7, 0.66],\n",
       " 'The Little Match-seller': [0.76, 0.57],\n",
       " 'The Wild Swans': [0.65, 0.63],\n",
       " 'The Swineherd': [0.59, 0.53],\n",
       " 'Little Tiny or Thumbelina': [0.64, 0.62],\n",
       " 'The Fir Tree': [0.66, 0.61],\n",
       " 'The Snow Man': [0.73, 0.57],\n",
       " 'The Brave Tin Soldier': [0.68, 0.63],\n",
       " 'The Little Mermaid': [0.71, 0.66],\n",
       " \"The Emperor's New Suit\": [0.63, 0.54],\n",
       " 'Jack the Dullard': [0.53, 0.51]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83937749-9164-4596-99a2-8bd1b800c9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T11:28:15.664628Z",
     "iopub.status.busy": "2021-10-20T11:28:15.664034Z",
     "iopub.status.idle": "2021-10-20T11:28:15.683921Z",
     "shell.execute_reply": "2021-10-20T11:28:15.683255Z",
     "shell.execute_reply.started": "2021-10-20T11:28:15.664579Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Hs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_114/5078201.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#average of Hs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mHs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(k+\"\\t\",round(np.mean(hs),3), round(np.std(hs),3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hs' is not defined"
     ]
    }
   ],
   "source": [
    "#average of Hs\n",
    "ranks = []\n",
    "for k in Hs.keys():\n",
    "    hs = Hs[k]\n",
    "    #print(k+\"\\t\",round(np.mean(hs),3), round(np.std(hs),3))\n",
    "    ranks.append((np.mean(hs),k))\n",
    "    \n",
    "ranks.sort()\n",
    "print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b11c3-5cde-43a3-8dd5-65d6865d8f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0a927-8f24-4fd1-962f-2d9c10a753c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## My clustering (all in a notebook for now, to go smoother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67391d4-3d4f-4e19-b5d0-eb879f585b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.preprocessing import TimeSeriesResampler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d824e09-8ac8-4e60-94eb-795bff641599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "def plot_hierarchy_2D(X, labels=[], title='Hierarchical Clustering Dendrogram', node_col='newspaper_event'):\n",
    "    #df.index = df[node_col]\n",
    "    #X = np.array(df[['X', 'Y']])\n",
    "\n",
    "    # setting distance_threshold=0 ensures we compute the full tree.\n",
    "    \n",
    "    new_shape = []\n",
    "    for el in X:\n",
    "        new_shape.append([float(e) for e in el])\n",
    "\n",
    "    new_shape = np.array(new_shape)\n",
    "    \n",
    "    model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "\n",
    "    model = model.fit(new_shape)\n",
    "    print(model.n_connected_components_, model.n_clusters_, model.labels_)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.title(title)\n",
    "    # plot the top three levels of the dendrogram\n",
    "    plot_dendrogram(model, truncate_mode='level', p=7, labels=labels)# df.index)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "    \n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a3dfe-1fe6-49f1-b790-b465ee02f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, warcs, warcs_vader, warcs_vad = [],[],[],[]\n",
    "for key in word_arcs.keys():\n",
    "    labels.append(key)\n",
    "    labels.append(key+\"_VAD\")\n",
    "    warcs+=word_arcs[key]\n",
    "    vader = word_arcs[key][0]\n",
    "    vad = word_arcs[key][1]\n",
    "    #vad_ = [e-.1 for e in vad]\n",
    "    warcs_vad.append(vad)\n",
    "    warcs_vader.append(vader)\n",
    "    #warcs_vad.append(vad_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e426940-a448-43c6-ba28-5af9bf633c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = 0,12\n",
    "series = warcs_vad[n:m]\n",
    "leng = min([len(e) for e in series])\n",
    "print(leng)\n",
    "serialized_warcs = to_time_series_dataset(series)\n",
    "resampled_warcs = TimeSeriesResampler(sz=3000).fit_transform(serialized_warcs) \n",
    "labels_ = clean_ls[n:m] #\n",
    "print(labels_)\n",
    "print([len(s) for s in series])\n",
    "plot_hierarchy_2D(resampled_warcs, labels=labels_, title=\"vad3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9c266-985f-4374-87f2-78d35ada8eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc98a5d-78a5-4b2b-92a7-9cba410e8dde",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-10-21T15:15:00.457842Z",
     "iopub.status.busy": "2021-10-21T15:15:00.457274Z",
     "iopub.status.idle": "2021-10-21T15:17:29.137355Z",
     "shell.execute_reply": "2021-10-21T15:17:29.136409Z",
     "shell.execute_reply.started": "2021-10-21T15:15:00.457791Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.9-py3-none-any.whl (319 kB)\n",
      "\u001b[K     |████████████████████████████████| 319 kB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from flair) (2021.8.3)\n",
      "Collecting huggingface-hub\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting torch!=1.8,>=1.5.0\n",
      "  Downloading torch-1.10.0-cp39-cp39-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 881.9 MB 2.1 kB/s s eta 0:00:01     |██████████████▎                 | 393.5 MB 109.4 MB/s eta 0:00:05 MB/s eta 0:00:02��████████████████        | 663.4 MB 129.1 MB/s eta 0:00:02     |████████████████████████▉       | 684.9 MB 119.0 MB/s eta 0:00:02[K     |██████████████████████████▊     | 736.1 MB 128.3 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting scikit-learn>=0.21.3\n",
      "  Downloading scikit_learn-1.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7 MB 67.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.9/site-packages (from flair) (4.62.0)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 38.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gensim<=3.8.3,>=3.4.0\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.4 MB 33.8 MB/s eta 0:00:01                     | 1.2 MB 33.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting conllu>=4.0\n",
      "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 565 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting transformers>=4.0.0\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 64.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 44.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (from flair) (4.6.3)\n",
      "Collecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.9/site-packages (from flair) (2.8.2)\n",
      "Collecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
      "Collecting more-itertools~=8.8.0\n",
      "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 587 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[K     |████████████████████████████████| 788 kB 66.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp39-cp39-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 49.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "Collecting hyperopt>=0.1.1\n",
      "  Downloading hyperopt-0.2.5-py2.py3-none-any.whl (965 kB)\n",
      "\u001b[K     |████████████████████████████████| 965 kB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gdown==3.12.2\n",
      "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.9/site-packages (from flair) (3.4.3)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.9/site-packages (from gdown==3.12.2->flair) (2.26.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from gdown==3.12.2->flair) (1.16.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from bpemb>=0.3.2->flair) (1.21.2)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.13.2-cp39-cp39-manylinux2010_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.7.1)\n",
      "Collecting smart_open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 2.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle\n",
      "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.9/site-packages (from hyperopt>=0.1.1->flair) (0.18.2)\n",
      "Collecting networkx>=2.2\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 25.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (8.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 50.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (3.10.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (5.4.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (21.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 46.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.9/site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from sacremoses->transformers>=4.0.0->flair) (8.0.1)\n",
      "Building wheels for collected packages: gdown, mpld3, gensim, overrides, segtok, sqlitedict, ftfy, langdetect, wikipedia-api\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9692 sha256=37ddba7d0e6b2cbecd3d395cb53f27d1afb8a6f34ec33d40caf422ae769fa586\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/19/65/a3/57172a39ac442300d84329fe2730327f7674bdfb2ab7ba3e74\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116678 sha256=990f6c37b2ee9ec188aed3cd79b1c962aa3b912b04f2f1a5ba29ce1da4ced648\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/a6/f4/e6/e40ff9021f6b3854af70fa8ea004f5ab95672817462df08fed\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.3-cp39-cp39-linux_x86_64.whl size=24328203 sha256=169eceaaebddd1b9063510dbcb6e7a6985e47277671576298217db45fcf1052e\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/ca/5d/af/618594ec2f28608c1d6ee7d2b7e95a3e9b06551e3b80a491d6\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10175 sha256=d1a054c1ed6933eecd60332fa91f739e094095c473cb8383018612f0fdfa99fe\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/7d/11/0e/73fdcb3d71d97e33c230900efe85923ee9d49515d050503174\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25018 sha256=f4f15562589e3836f5cc7268a24d54740fd36f0afe0791bd73fed77298d74b43\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/e2/18/5e/97893138f61cd5cdb9d1e8e3d10f138910b0ecd3a2370ba0da\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14376 sha256=b62bc20ea539d26ad0b1548bb7ab532e77d935db0ba8e901ca0e442688dc8e25\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/ce/4d/44/3ab767a772715f6201d85f49d454db3e08f283cece4c2e356c\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41913 sha256=ec65a2651ebd0f74f5ce67b48db3a22e1d36cff6451605c748c52bbcd08d7273\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/3d/ee/4b/03a4e2e591ea56687aff999edc83827a2ace523baab75b8e41\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=d0ff66396f34f374801b3e4349a225252b7922e82914fbf8d28a95212c79cd51\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13462 sha256=35067a0295f80e1a7a27027fa749ca32647b864687fa4c27f707868129c37ab1\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/c7/cf/1a/c300428dd51654cdadc921abdff75acaa7cc80b7151a2f0695\n",
      "Successfully built gdown mpld3 gensim overrides segtok sqlitedict ftfy langdetect wikipedia-api\n",
      "Installing collected packages: smart-open, joblib, filelock, wrapt, tokenizers, threadpoolctl, sentencepiece, sacremoses, overrides, networkx, importlib-metadata, huggingface-hub, gensim, cloudpickle, wikipedia-api, transformers, torch, tabulate, sqlitedict, segtok, scikit-learn, mpld3, more-itertools, langdetect, konoha, janome, hyperopt, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.3\n",
      "    Uninstalling importlib-metadata-4.6.3:\n",
      "      Successfully uninstalled importlib-metadata-4.6.3\n",
      "Successfully installed bpemb-0.3.3 cloudpickle-2.0.0 conllu-4.4.1 deprecated-1.2.13 filelock-3.3.1 flair-0.9 ftfy-6.0.3 gdown-3.12.2 gensim-3.8.3 huggingface-hub-0.0.19 hyperopt-0.2.5 importlib-metadata-3.10.1 janome-0.4.1 joblib-1.1.0 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 networkx-2.6.3 overrides-3.1.0 sacremoses-0.0.46 scikit-learn-1.0 segtok-1.5.10 sentencepiece-0.1.95 smart-open-5.2.1 sqlitedict-1.7.0 tabulate-0.8.9 threadpoolctl-3.0.0 tokenizers-0.10.3 torch-1.10.0 transformers-4.11.3 wikipedia-api-0.5.4 wrapt-1.13.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83928ef4-7e71-4b9a-9a63-31b8f5728fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:17:29.149036Z",
     "iopub.status.busy": "2021-10-21T15:17:29.148865Z",
     "iopub.status.idle": "2021-10-21T15:17:31.114772Z",
     "shell.execute_reply": "2021-10-21T15:17:31.114066Z",
     "shell.execute_reply.started": "2021-10-21T15:17:29.149015Z"
    }
   },
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b621dc0-7020-4ea7-815a-f45fe87381db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:18:46.971030Z",
     "iopub.status.busy": "2021-10-21T15:18:46.970485Z",
     "iopub.status.idle": "2021-10-21T15:19:50.496476Z",
     "shell.execute_reply": "2021-10-21T15:19:50.494087Z",
     "shell.execute_reply.started": "2021-10-21T15:18:46.970996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-21 17:18:47,215 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /tmp/tmpsc41ilqg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265512723/265512723 [00:06<00:00, 39566059.76B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-21 17:18:54,036 copying /tmp/tmpsc41ilqg to cache at /home/ucloud/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-21 17:18:54,257 removing temp file /tmp/tmpsc41ilqg\n",
      "2021-10-21 17:18:54,290 loading file /home/ucloud/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bc659e4ed542b2bae5f09610c31147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d9bd52ce7347a4952a86d374a5cd4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc916555b1544bc7a95abb3dabdedfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2faaf5c00bb43cfa302a787142be86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flair_sentiment = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e14bc38-33c6-4306-91f1-3669e5335fe4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:21:18.543505Z",
     "iopub.status.busy": "2021-10-21T15:21:18.542885Z",
     "iopub.status.idle": "2021-10-21T15:21:18.548983Z",
     "shell.execute_reply": "2021-10-21T15:21:18.548156Z",
     "shell.execute_reply.started": "2021-10-21T15:21:18.543469Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = \"I am so frustrated with you right now\".split()\n",
    "s = flair.data.Sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe68c62-9403-4c0c-934d-28dca6a8efc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:21:19.233599Z",
     "iopub.status.busy": "2021-10-21T15:21:19.232511Z",
     "iopub.status.idle": "2021-10-21T15:22:02.496668Z",
     "shell.execute_reply": "2021-10-21T15:22:02.495629Z",
     "shell.execute_reply.started": "2021-10-21T15:21:19.233527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NEGATIVE (0.9987)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair_sentiment.predict(s)\n",
    "total_sentiment = s.labels\n",
    "total_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d49177-1aa0-48a0-8fb9-0cccd5171d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:25:03.721336Z",
     "iopub.status.busy": "2021-10-21T15:25:03.720886Z",
     "iopub.status.idle": "2021-10-21T15:26:12.119344Z",
     "shell.execute_reply": "2021-10-21T15:26:12.118079Z",
     "shell.execute_reply.started": "2021-10-21T15:25:03.721308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp39-cp39-manylinux2010_x86_64.whl (458.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.4 MB 9.1 kB/s eta 0:00:0103     |████████████████████████████    | 400.4 MB 3.0 MB/s eta 0:00:20\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 79 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 62.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.17.3)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 56.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.39.0)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 49.7 MB/s eta 0:00:01     |█████████████████████████████   | 13.5 MB 49.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 72.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 51.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 203 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.34.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 43.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Building wheels for collected packages: clang, termcolor, wrapt\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=26a02bbc88651466264739fb566cd45f3c99cbcfd502bb12dd0d935a2a5f4cd6\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/3a/ce/7a/27094f689461801c934296d07078773603663dfcaca63bb064\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=93ab57aee47b1207bf432a1ce34770f5140ef8a36ddb10734dd884471f49c4a6\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=36920 sha256=a269dd065ff1cc8b36002c0d59d946b2141ec5a6daf4b5470c8411fcf1d1648d\n",
      "  Stored in directory: /home/ucloud/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
      "Successfully built clang termcolor wrapt\n",
      "Installing collected packages: six, tensorboard-data-server, numpy, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.13.2\n",
      "    Uninstalling wrapt-1.13.2:\n",
      "      Successfully uninstalled wrapt-1.13.2\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.1\n",
      "    Uninstalling tensorboard-2.4.1:\n",
      "      Successfully uninstalled tensorboard-2.4.1\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.3.0\n",
      "    Uninstalling h5py-3.3.0:\n",
      "      Successfully uninstalled h5py-3.3.0\n",
      "Successfully installed astunparse-1.6.3 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-pasta-0.2.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 numpy-1.19.5 opt-einsum-3.3.0 six-1.15.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3d5daa-cb1e-49e1-b456-604c2fee9ed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T15:26:12.134414Z",
     "iopub.status.busy": "2021-10-21T15:26:12.134062Z",
     "iopub.status.idle": "2021-10-21T15:26:14.584604Z",
     "shell.execute_reply": "2021-10-21T15:26:14.583545Z",
     "shell.execute_reply.started": "2021-10-21T15:26:12.134386Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 17:26:12.638216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-21 17:26:12.638309: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02707c9d-32d1-448b-b2a9-6ed73e5c45e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
